{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNPGU6pizgmPy662JtPKOu3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 체인 여러개 연결"],"metadata":{"id":"sdUPtGET_Nms"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OQuK1g4A_KFc"},"outputs":[],"source":["from langchain_community.chat_models import ChatOllama\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","\n","\n","llm = ChatOllama(model=\"steamdj/llama3.1-cpu-only:latest\")\n","\n","# 첫번째 체인\n","prompt1 = ChatPromptTemplate.from_template(\"[{korean_input}] translate the question into English. Don't say anything else, just translate it.\")\n","chain1 = (\n","    prompt1\n","    | llm\n","    | StrOutputParser()\n",")\n","message1 = chain1.invoke({\"korean_input\": \"주식이 뭐야?\"})\n","print(f'message1: {message1}') # What is a stock?\n","\n","# 두번째 체인\n","prompt2 = ChatPromptTemplate.from_messages([\n","    (\"system\", \"You are a helpful, professional assistant named 똑똑이. answer the question in Korean\"),\n","    (\"user\", \"{input}\")\n","])\n","chain2 = (\n","    {\"input\": chain1}\n","    | prompt2\n","    | llm\n","    | StrOutputParser()\n",")\n","message2 = chain2.invoke({\"korean_input\": \"주식이 뭐야?\"})\n","print(f'message2: {message2}') # 주식은 한 회사의 소유권을 나타내는 증권입니다. 즉, 특정 기업에 투자하여 (중략)"]},{"cell_type":"markdown","source":["**출력파서(Output Parser)**\n","\n","LangChain의 출력파서는 언어 모델(LLM)의 출력을 더 유용하고 구조화된 형태로 변환하는 중요한 컴포넌트입니다.\n","\n","**출력파서의 역할**\n","\n","- LLM의 출력을 받아 더 적합한 형식으로 변환\n","- 구조화된 데이터 생성에 매우 유용\n","- LangChain 프레임워크에서 다양한 종류의 출력 데이터를 파싱하고 처리\n","\n","**채팅 메시지를 문자열로 변환하는 출력 구문 분석기**\n","\n","StrOutputParser, PydanticOuputParser, JsonOutputParser, StructuredOuputParser 등이 있음\n","\n","- OutputParser 사용\n","    - 채팅 메시지를 문자열로 변환하는 출력 구문 분석기\n","        - StrOutputParser, PydanticOuputParser, JsonOutputParser, StructuredOuputParser 등\n","      "],"metadata":{"id":"uELFaxIF_iA2"}},{"cell_type":"markdown","source":["## 체인 병렬 실행"],"metadata":{"id":"feX_QS52_RVU"}},{"cell_type":"code","source":["from langchain_community.chat_models import ChatOllama\n","from langchain_core.prompts import ChatPromptTemplate\n","\n","\n","llm = ChatOllama(model=\"steamdj/llama3.1-cpu-only:latest\")\n","\n","joke_chain = (\n","    ChatPromptTemplate.from_template(\"{topic}에 관련해서 짧은 농담 말해줘\")\n","    | llm)\n","poem_chain = (\n","    ChatPromptTemplate.from_template(\"{topic}에 관련해서 시 2줄 써줘\")\n","    | llm)\n","\n","# map_chain = {\"joke\": joke_chain, \"poem\": poem_chain} # 체인에서 이처럼 사용할 때, 자동으로 RunnableParallel 사용됨\n","# map_chain = RunnableParallel({\"joke\": joke_chain, \"poem\": poem_chain})\n","\n","from langchain_core.runnables import RunnableParallel\n","map_chain = RunnableParallel(joke=joke_chain, poem=poem_chain)\n","\n","output = map_chain.invoke({\"topic\": \"애플\"})\n","print(output)"],"metadata":{"id":"Ovlqjgy3_ogv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### OutputParser 사용 예"],"metadata":{"id":"prPAJQrX_0hf"}},{"cell_type":"code","source":["from langchain_core.output_parsers import StrOutputParser\n","\n","chain = prompt | llm | StrOutputParser()\n","chain.invoke({\"input\": \"What is stock?\"})"],"metadata":{"id":"zSkEH8k7_z1x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### StrOutputParser"],"metadata":{"id":"vzcO1yvw_-40"}},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate\n","from langchain_community.chat_models import ChatOllama\n","\n","llm = ChatOllama(model=\"steamdj/llama3.1-cpu-only:latest\")\n","prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"You are a helpful, professional assistant named 똑똑이. Introduce yourself first, and answer the questions. answer me in Korean no matter what. \"),\n","    (\"user\", \"{input}\")\n","])\n","\n","from langchain_core.output_parsers import StrOutputParser\n","\n","chain = prompt | llm | StrOutputParser()\n","output = chain.invoke({\"input\": \"What is stock?\"})\n","print(output)"],"metadata":{"id":"L-0L4e-f_4e6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### CSV parser"],"metadata":{"id":"m5uS9ReqACyz"}},{"cell_type":"code","source":["from langchain_core.prompts import PromptTemplate\n","from langchain_community.chat_models import ChatOllama\n","\n","prompt = PromptTemplate(\n","    template=\"List five {subject}.\\n{format_instructions}\",\n","    input_variables=[\"subject\"],\n","    partial_variables={\"format_instructions\": format_instructions},\n",")\n","\n","llm = ChatOllama(model=\"steamdj/llama3.1-cpu-only:latest\")\n","\n","chain = prompt | llm | output_parser\n","\n","chain.invoke({\"subject\": \"popular Korean cusine\"})"],"metadata":{"id":"w4s6DOlh_5_v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### JSON parser"],"metadata":{"id":"YNaR8jYsAFnF"}},{"cell_type":"code","source":["from langchain_core.prompts import PromptTemplate\n","from langchain_community.chat_models import ChatOllama\n","from langchain_core.output_parsers import JsonOutputParser\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","\n","# 자료구조 정의 (pydantic)\n","class CusineRecipe(BaseModel):\n","    name: str = Field(description=\"name of a cusine\")\n","    recipe: str = Field(description=\"recipe to cook the cusine\")\n","\n","# 출력 파서 정의\n","output_parser = JsonOutputParser(pydantic_object=CusineRecipe)\n","\n","format_instructions = output_parser.get_format_instructions()\n","\n","print(format_instructions)"],"metadata":{"id":"M3Ol1RsMAG5d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Pydantic parser"],"metadata":{"id":"InRFARmgAJH6"}},{"cell_type":"code","source":["pip install langchain-teddynote"],"metadata":{"id":"tgmtb29zAKyW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Without Pydantic parser\n","from langchain_teddynote.messages import stream_response\n","from langchain_community.chat_models import ChatOllama\n","from langchain_core.output_parsers import PydanticOutputParser\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","\n","llm = ChatOllama(model=\"llama3.1:latest\")\n","\n","email_conversation = \"\"\"\n","From: 김상무 (sangmu.kim@greenmobility.co.kr)\n","To: 이대리 (daeri.lee@ecotechsolutions.com)\n","Subject: \"E-STORE\" 에너지 저장 장치 유통 협력 및 미팅 일정 제안\n","\n","안녕하세요, 이대리 대리님,\n","\n","저는 에코테크의김상무 상무입니다. 최근 보도자료를 통해 귀사의 신규 친환경 에너지 저장 장치 \"E-STORE\"에 대해 알게 되었>습니다. 에코테크는 친환경 에너지 솔루션과 관련된 기술 개발 및 유통 분야에서 혁신과 품질을 선도하는 기업으로, 이 분야에서의 장기적인 경험과 전문성을 가지고 있습니다.\n","\n","E-STORE 모델에 대한 상세한 브로슈어를 요청드립니다. 특히 기술 사양, 저장 용량, 그리고 효율성 측면에 대한 정보가 필요합\n","니다. 이를 통해 저희가 제안할 솔루션 전략과 마케팅 계획을 보다 구체화할 수 있을 것입니다.\n","\n","또한, 협력 가능성을 더 깊이 논의하기 위해 다음 주 화요일(1월 15일) 오전 10시에 미팅을 제안합니다. 귀사 사무실에서 만나\n"," 이야기를 나눌 수 있을까요?\n","\n","감사합니다.\n","\n","김상무\n","상무이사\n","에코테크\n","\n","\"\"\"\n","\n","from itertools import chain\n","from langchain_core.prompts import PromptTemplate\n","\n","prompt = PromptTemplate.from_template(\n","    \"다음의 이메일 내용중 중요한 내용을 추출해 주세요.\\n\\n{email_conversation}\"\n",")\n","\n","\n","chain = prompt | llm\n","\n","\n","answer = chain.stream({\"email_conversation\": email_conversation})\n","\n","output = stream_response(answer, return_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":404},"id":"Cw90J89rANh-","executionInfo":{"status":"error","timestamp":1725939392722,"user_tz":-540,"elapsed":366,"user":{"displayName":"정영운","userId":"02028984778684752470"}},"outputId":"d90499ba-60d3-4a7c-bf18-3898c6891f4d"},"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'langchain_teddynote'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-78b5a04fa424>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_teddynote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstream_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOllama\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_parsers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPydanticOutputParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpydantic_v1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_teddynote'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["# With Pydantic parser\n","import re\n","import json\n","from langchain_teddynote.messages import stream_response\n","from langchain_community.chat_models import ChatOllama\n","from langchain_core.output_parsers import PydanticOutputParser\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","\n","llm = ChatOllama(model=\"llama3.1:latest\")\n","\n","email_conversation = \"\"\"\n","From: 김상무 (sangmu.kim@greenmobility.co.kr)\n","To: 이대리 (daeri.lee@ecotechsolutions.com)\n","Subject: \"E-STORE\" 에너지 저장 장치 유통 협력 및 미팅 일정 제안\n","\n","안녕하세요, 이대리 대리님,\n","\n","저는 에코테크의김상무 상무입니다. 최근 보도자료를 통해 귀사의 신규 친환경 에너지 저장 장치 \"E-STORE\"에 대해 알게 되었>습니다. 에코테크는 친환경 에너지 솔루션과 관련된 기술 개발 및 유통 분야에서 혁신과 품질을 선도하는 기업으로, 이 분야에서의 장기적인 경험과 전문성을 가지고 있습니다.\n","\n","E-STORE 모델에 대한 상세한 브로슈어를 요청드립니다. 특히 기술 사양, 저장 용량, 그리고 효율성 측면에 대한 정보가 필요합\n","니다. 이를 통해 저희가 제안할 솔루션 전략과 마케팅 계획을 보다 구체화할 수 있을 것입니다.\n","\n","또한, 협력 가능성을 더 깊이 논의하기 위해 다음 주 화요일(1월 15일) 오전 10시에 미팅을 제안합니다. 귀사 사무실에서 만나\n"," 이야기를 나눌 수 있을까요?\n","\n","감사합니다.\n","\n","김상무\n","상무이사\n","에코테크\n","\n","\"\"\"\n","\n","from itertools import chain\n","from langchain_core.prompts import PromptTemplate\n","\n","class EmailSummary(BaseModel):\n","    person: str = Field(description=\"메일을 보낸 사람\")\n","    email: str = Field(description=\"메일을 보낸 사람의 이메일 주소\")\n","    subject: str = Field(description=\"메일 제목\")\n","    summary: str = Field(description=\"메일 본문을 요약한 텍스트\", default=\"N/A\")\n","    date: str = Field(description=\"메일 본문에 언급된 미팅 날짜와 시간\", default=\"N/A\")\n","\n","def preprocess_json(json_str):\n","    # 불필요한 공백 제거\n","    json_str = json_str.strip()\n","\n","    # 필드 값의 시작과 끝에 있는 따옴표를 제거하고 내부의 따옴표를 이스케이프 처리\n","    def process_value(match):\n","        key = match.group(1)\n","        value = match.group(2).strip()\n","        if value.startswith('\"') and value.endswith('\"'):\n","            value = value[1:-1]\n","        # 값에 있는 모든 따옴표를 이스케이프 처리\n","        value = value.replace('\"', '\\\\\"')\n","        return f'\"{key}\": \"{value}\"'\n","\n","    # 모든 필드의 값을 처리\n","    json_str = re.sub(r'\"(\\w+)\":\\s*(.+?)(?=,|\\s*}|$)', process_value, json_str)\n","\n","    # 마지막 필드 뒤에 쉼표가 있다면 제거\n","    json_str = re.sub(r',\\s*}$', '}', json_str)\n","\n","    return json_str\n","\n","# PydanticOutputParser 생성\n","parser = PydanticOutputParser(pydantic_object=EmailSummary)\n","# instruction 을 출력합니다.\n","print(parser.get_format_instructions())\n","\n","#You are a helpful assistant. Please answer the following questions in KOREAN.\n","\n","prompt = PromptTemplate.from_template(\n","\"\"\"\n","You are a helpful assistant. Extract the main contents of the email and provide the result as a valid JSON object.\n","Your response should contain ONLY the JSON object, without any additional text or explanation.\n","Ensure that the JSON is properly formatted, with all values enclosed in double quotes and any internal quotes escaped.\n","Do not use line breaks within the JSON object.\n","The JSON MUST include exactly these keys: \"person\", \"email\", and \"subject\".\n","If information for any field is not available, use \"N/A\" as the value.\n","\n","QUESTION:\n","{question}\n","\n","EMAIL CONVERSATION:\n","{email_conversation}\n","\n","FORMAT:\n","{format}\n","\n","RESPONSE (ONLY JSON):\n","\"\"\"\n",")\n","\n","# format 에 PydanticOutputParser의 부분 포맷팅(partial) 추가\n","prompt = prompt.partial(format=parser.get_format_instructions())\n","\n","chain = prompt | llm\n","\n","\n","# chain 을 실행하고 결과를 출력합니다.\n","response = chain.stream(\n","    {\n","        \"email_conversation\": email_conversation,\n","        \"question\": \"이메일 내용중 주요 내용을 추출해 주세요.\",\n","    }\n",")\n","\n","\n","# 유니코드 제어 문자 제거 함수\n","import unicodedata\n","\n","def remove_control_characters(s):\n","    return \"\".join(ch for ch in s if unicodedata.category(ch)[0] != \"C\")\n","\n","# LLM 출력 후 전처리 및 파싱\n","output = stream_response(response, return_output=True)\n","output = remove_control_characters(output)\n","print(\"Raw LLM output:\")\n","print(output)\n","\n","try:\n","    preprocessed_output = preprocess_json(output)\n","    print(\"Preprocessed output:\")\n","    print(preprocessed_output)\n","\n","    json_data = json.loads(preprocessed_output)\n","\n","    structured_output = EmailSummary(**json_data)\n","    print(\"Structured output:\")\n","    print(structured_output)\n","except json.JSONDecodeError as e:\n","    print(f\"JSON Decode Error: {e}\")\n","    print(\"Preprocessed output:\")\n","    print(preprocessed_output)\n","except ValidationError as e:\n","    print(f\"Pydantic Validation Error: {e}\")\n","    print(\"JSON data:\")\n","    print(json_data)\n","except Exception as e:\n","    print(f\"Error: {type(e).__name__} - {e}\")\n","    print(\"Raw output:\")\n","    print(output)"],"metadata":{"id":"YZIBfFSQAPx2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### HuggingFace-Hub 설치"],"metadata":{"id":"sllZf4D-AeVa"}},{"cell_type":"code","source":["pip install huggingface-hub"],"metadata":{"id":"OZ_ZNEfxAhrP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**모델 다운로드**\n","\n","명령어 형식:  `HuggingFace Repo` \\ .gguf 파일명\\ local-dir 설정 \\심볼릭 링크 설정"],"metadata":{"id":"Wl7uzHvlAkLa"}},{"cell_type":"code","source":["huggingface-cli download \\\n","  heegyu/EEVE-Korean-Instruct-10.8B-v1.0-GGUF \\\n","  ggml-model-Q5_K_M.gguf \\\n","  --local-dir [본인의_컴퓨터_다운로드폴더_경로] \\\n","  --local-dir-use-symlinks False"],"metadata":{"id":"VhSYsIBGAlmu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Modelfile 예시"],"metadata":{"id":"oXPLMQogAqUx"}},{"cell_type":"code","source":["FROM ggml-model-Q5_K_M.gguf\n","\n","TEMPLATE \"\"\"{{- if .System }}\n","<s>{{ .System }}</s>\n","{{- end }}\n","<s>Human:\n","{{ .Prompt }}</s>\n","<s>Assistant:\n","\"\"\"\n","# 시스템 메시지 설정\n","SYSTEM \"\"\"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\"\"\"\n","\n","TEMPERATURE 0 # 온도 설정 (높을수록 창의적, 낮을수록 정확함)\n","PARAMETER stop <s>\n","PARAMETER stop </s>"],"metadata":{"id":"DgMmzLNFAoS1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###  모델파일을 기준으로  LLM(gguf) 설치하기"],"metadata":{"id":"JodV5U2MAwMe"}},{"cell_type":"code","source":["# ollma create [만들이름] -f [모델파일경로]\n","ollama create Test1-10.8B -f EEVE-Korean-Instruct-10.8B-v1.0-GGUF/Modelfile"],"metadata":{"id":"ferIJ3NmAx29"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["$ pip install langchain langchain-community langchain-core\n","$ pip install langchain-openai sse_starlette pydantic==1.10.13\n","$ pip install sse_starlette\n","$ pip install pydantic==1.10.13"],"metadata":{"id":"nJORG1fFA31w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["라이브러리 추가 설치"],"metadata":{"id":"7BE8Mp2sA3le"}},{"cell_type":"code","source":[],"metadata":{"id":"YPBp7-M5A6sV"},"execution_count":null,"outputs":[]}]}